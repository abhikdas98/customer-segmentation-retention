ğŸ§  Customer Churn Prediction System â€” Production-Ready ML Pipeline

An end-to-end Machine Learning system that performs:

ğŸ“Š Customer Segmentation (RFM + KMeans)

ğŸ” Churn Prediction (Logistic Regression)

ğŸ—„ MongoDB Data Storage

âš¡ FastAPI Inference API

ğŸ³ Dockerized Deployment

ğŸŒ© AWS EC2 Cloud Hosting

ğŸ” CI/CD via GitHub Actions

Built with production-grade architecture and MLOps best practices.

ğŸŒ Live Deployment
ğŸš€ Swagger UI
http://13.61.65.27:8000/docs
ğŸ©º Health Check
http://13.61.65.27:8000/health

CI/CD automatically deploys updates on every push to main.

ğŸ’¡ Why This Project Stands Out

Unlike typical ML notebook projects, this system demonstrates:

Production-grade API deployment

Docker multi-container architecture

MongoDB integration

Batch-safe large data ingestion (400K+ records)

Memory tuning for micro cloud instance

CI/CD automation

Model version pinning

Health monitoring endpoint

Real-world debugging in cloud environment

This is a deployment-focused ML system, not just a modeling exercise.

ğŸ— System Architecture
              GitHub Push
                   â†“
          GitHub Actions (CI/CD)
                   â†“
               AWS EC2
                   â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Docker Compose       â”‚
        â”‚                      â”‚
        â”‚  FastAPI Container   â”‚
        â”‚        â†“             â”‚
        â”‚  Churn Model         â”‚
        â”‚        â†“             â”‚
        â”‚  MongoDB Container   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
ğŸ“‚ Project Structure
customer-segmentation-retention/
â”‚
â”œâ”€â”€ app/
â”‚   â””â”€â”€ main.py                  # FastAPI application
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ insert_data.py           # Safe MongoDB batch seeding
â”‚   â”œâ”€â”€ churn_model.py           # Prediction logic
â”‚   â”œâ”€â”€ feature_engineering.py   # RFM + behavioral features
â”‚   â”œâ”€â”€ config.py
â”‚   â””â”€â”€ logger.py
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ logistic_model.pkl
â”‚   â””â”€â”€ scaler.pkl
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ raw/online_retail.csv
â”‚
â”œâ”€â”€ .github/workflows/
â”‚   â””â”€â”€ deploy.yml               # CI/CD automation
â”‚
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
ğŸ“Š Machine Learning Pipeline
1ï¸âƒ£ Customer Segmentation

RFM feature engineering

Log transformation

KMeans clustering

Silhouette score validation

2ï¸âƒ£ Churn Modeling

Logistic Regression

Threshold tuning for churn recall optimization

ROC-AUC evaluation

Feature importance interpretation

Data leakage detection & correction

Final production model uses:

Frequency

Monetary

AvgOrderValue

ğŸ“ˆ Model Performance
Metric	Score
Accuracy	~74%
ROC-AUC	~0.77
Churn Recall (after tuning)	0.82
ğŸ“¡ Example API Usage
Request
POST /predict_churn_by_id
{
  "customer_id": 12347
}
Response
{
  "customer_id": 12347,
  "features": {
    "Frequency": 7,
    "Monetary": 4310.0,
    "AvgOrderValue": 615.71
  },
  "prediction": {
    "churn_probability": 0.07,
    "churn_prediction": 0
  }
}
ğŸ³ Running Locally with Docker
Build & Start Containers
docker compose build --no-cache
docker compose up
Seed MongoDB (One-time)
docker exec -it churn-api python -m src.insert_data
Access API

Swagger:

http://localhost:8000/docs
ğŸ” CI/CD Automation

Push to main

GitHub Actions SSH into EC2

Pull latest code

Rebuild Docker containers

Restart API

Fully automated deployment pipeline.

ğŸ›  Production Engineering Challenges Solved
ğŸ”¹ MongoDB OOM Crash

Fixed WiredTiger cache size for micro instance:

command: ["mongod", "--wiredTigerCacheSizeGB", "0.25"]
ğŸ”¹ Large Dataset Ingestion

Implemented chunk-based batch insertion to safely seed 400K+ records.

ğŸ”¹ Docker Networking Issue

Replaced localhost with Docker service name for container communication.

ğŸ”¹ Version Mismatch

Pinned scikit-learn version to ensure consistent model deserialization.

ğŸ”¹ Health Monitoring

Implemented /health endpoint for production validation.

ğŸ” Reproducibility

All dependencies pinned in requirements.txt

Docker ensures consistent runtime

Environment-independent deployment

ğŸš€ Future Improvements

HTTPS with Nginx reverse proxy

Rate limiting

Monitoring & metrics dashboard

Model versioning system

CloudWatch integration

Automated retraining pipeline

ğŸ‘¨â€ğŸ’» Author

Abhik Das
Data Science | Machine Learning | MLOps